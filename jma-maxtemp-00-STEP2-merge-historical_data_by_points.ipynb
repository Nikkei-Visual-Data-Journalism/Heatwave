{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57bce8b1",
   "metadata": {},
   "source": [
    "# jma-maxtemp-00-STEP2-merge-historical_data_by_points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c52473b",
   "metadata": {},
   "source": [
    "* 作業内容\n",
    "    * jma-maxtemp-00-STEP1-get-historical_data_by_pointsで取得した各観測時点のヒストリカルデータをまとめる\n",
    "    * 県別の日次の最高気温の推移を作成\n",
    "    * データ内容（欠損値）をチェック\n",
    "\n",
    "* 不定期運転\n",
    "    * 最初のデータ作成時\n",
    "    * STEP1で過去データを遡及して取得して期間をのばしたとき\n",
    "    * 月次データの更新など（やりたければ）\n",
    "<br><br>\n",
    "* 次のステップ\n",
    "    * 最新のデータと統合して、描画用のデータを作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "005459af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbe48d1",
   "metadata": {},
   "source": [
    "観測地点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d69d05a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#観測地点の一覧\n",
    "url = 'https://raw.githubusercontent.com/Nikkei-Visual-Data-Journalism/Heatwave/main/data-maxtemp/meta/points_list.csv'\n",
    "points = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0c52a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#地点、日付の組み合わせ\n",
    "prec_no = set(points.prec_no)\n",
    "dates = pd.date_range('1950-01-01','2023-07-01',freq='MS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af40e07",
   "metadata": {},
   "source": [
    "取得済みのデータを呼び出し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bca79de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#観測地点ごとの過去データ\n",
    "file_dir = \"./data-maxtemp/timeseries-data-by-points/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7968cecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ダウンロード済みファイル\n",
    "file_list= glob.glob(f'{file_dir}data-raw/prec-*/**/*.csv', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33b109d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"/prec-(\\d+)/jma-maxtemp-hs-\\d+-(\\d+)\\.csv$\"\n",
    "data_list = []\n",
    "\n",
    "for f in file_list:\n",
    "    prec, yyyymm = re.search(pattern, f).groups()\n",
    "    data =  {'prec_no': int(prec), 'yyyymm':yyyymm,'data':1,'filepath':f}\n",
    "    data_list.append(data)\n",
    "    \n",
    "retrieved = pd.DataFrame(data_list)\n",
    "retrieved.yyyymm = pd.to_datetime(retrieved.yyyymm, format='%Y%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b86bc7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prec_no</th>\n",
       "      <th>yyyymm</th>\n",
       "      <th>data</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>2010-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>./data-maxtemp/timeseries-data-by-points/data-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>2003-08-01</td>\n",
       "      <td>1</td>\n",
       "      <td>./data-maxtemp/timeseries-data-by-points/data-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>1</td>\n",
       "      <td>./data-maxtemp/timeseries-data-by-points/data-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>./data-maxtemp/timeseries-data-by-points/data-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>2009-03-01</td>\n",
       "      <td>1</td>\n",
       "      <td>./data-maxtemp/timeseries-data-by-points/data-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prec_no     yyyymm  data                                           filepath\n",
       "0       64 2010-02-01     1  ./data-maxtemp/timeseries-data-by-points/data-...\n",
       "1       64 2003-08-01     1  ./data-maxtemp/timeseries-data-by-points/data-...\n",
       "2       64 2016-10-01     1  ./data-maxtemp/timeseries-data-by-points/data-...\n",
       "3       64 2016-04-01     1  ./data-maxtemp/timeseries-data-by-points/data-...\n",
       "4       64 2009-03-01     1  ./data-maxtemp/timeseries-data-by-points/data-..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc69cac",
   "metadata": {},
   "source": [
    "データを統合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47c8aae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished: 11\n",
      "finished: 12\n",
      "finished: 13\n",
      "finished: 14\n",
      "finished: 15\n",
      "finished: 16\n",
      "finished: 17\n",
      "finished: 18\n",
      "finished: 19\n",
      "finished: 20\n",
      "finished: 21\n",
      "finished: 22\n",
      "finished: 23\n",
      "finished: 24\n",
      "finished: 31\n",
      "finished: 32\n",
      "finished: 33\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m     data_agg\u001b[38;5;241m.\u001b[39mloc[data_agg\u001b[38;5;241m.\u001b[39mpoints_no\u001b[38;5;241m.\u001b[39misin(capitol),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapitol\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m#日付、年\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     data_agg\u001b[38;5;241m.\u001b[39mdate \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_agg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     data_agg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data_agg\u001b[38;5;241m.\u001b[39mdate\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39myear\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#地点ごとのデータを出力\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:1046\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1044\u001b[0m             result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1045\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, ABCSeries):\n\u001b[0;32m-> 1046\u001b[0m     cache_array \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_listlike\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1047\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache_array\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m   1048\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:248\u001b[0m, in \u001b[0;36m_maybe_cache\u001b[0;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_cache(arg):\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cache_array\n\u001b[0;32m--> 248\u001b[0m unique_dates \u001b[38;5;241m=\u001b[39m \u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_dates) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(arg):\n\u001b[1;32m    250\u001b[0m     cache_dates \u001b[38;5;241m=\u001b[39m convert_listlike(unique_dates, \u001b[38;5;28mformat\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/pandas/core/algorithms.py:389\u001b[0m, in \u001b[0;36munique\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique\u001b[39m(values):\n\u001b[1;32m    296\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;124;03m    Return unique values based on a hash table.\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;124;03m    array([('a', 'b'), ('b', 'a'), ('a', 'c')], dtype=object)\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munique_with_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/pandas/core/algorithms.py:428\u001b[0m, in \u001b[0;36munique_with_mask\u001b[0;34m(values, mask)\u001b[0m\n\u001b[1;32m    426\u001b[0m table \u001b[38;5;241m=\u001b[39m hashtable(\u001b[38;5;28mlen\u001b[39m(values))\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 428\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m uniques\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_all = pd.DataFrame()\n",
    "\n",
    "for prec in prec_no:\n",
    "    filepaths = retrieved[retrieved.prec_no==prec].dropna(subset='filepath').filepath.to_list()\n",
    "    data_agg = pd.DataFrame()\n",
    "\n",
    "    for filepath in filepaths:\n",
    "        data_monthly = pd.read_csv(filepath)     \n",
    "        #)や]が入っているので掃除\n",
    "        data_monthly.maxtemp = data_monthly.maxtemp.apply(lambda x: re.sub(r'[^\\d\\.-]', '', str(x)))\n",
    "        data_monthly.maxtemp = pd.to_numeric(data_monthly.maxtemp, errors='coerce').astype(float)\n",
    "        #まとめる\n",
    "        data_agg = pd.concat([data_agg, data_monthly])\n",
    "        #都道府県情報\n",
    "        pref_dic = points.set_index('prec_no').pref.to_dict()\n",
    "        data_agg['pref'] = data_agg.prec_no.map(pref_dic)\n",
    "        #都道府県庁所在地\n",
    "        capitol = points[points.capitol==1]['観測所番号'].to_list()\n",
    "        data_agg['capitol'] = None\n",
    "        data_agg.loc[data_agg.points_no.isin(capitol),'capitol'] = 1\n",
    "        #日付、年\n",
    "        data_agg.date = pd.to_datetime(data_agg.date)\n",
    "        data_agg['year'] = data_agg.date.dt.year\n",
    "    #地点ごとのデータを出力\n",
    "    output_dir = f'{file_dir}data-agg-by-points/jma-maxtemp-hs-{prec}-merged.csv'\n",
    "    data_agg.to_csv(output_dir, index=False)\n",
    "    print(f'finished: {prec}')\n",
    "        \n",
    "    #１つのファイルに統合\n",
    "    data_all = pd.concat([data_all,data_agg])\n",
    "    \n",
    "#output_dir = f'{file_dir}data-agg-by-points/jma-maxtemp-hs-all-merged.csv'\n",
    "#data_all.to_csv(output_dir, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb19f3ed",
   "metadata": {},
   "source": [
    "真夏日、猛暑日を計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893523c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#県内の最高温度\n",
    "df_count = data_all.groupby(['date','year','pref']).maxtemp.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76f6fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#県庁所在地の最高温度をつけたす\n",
    "capitol = data_all[data_all.capitol==1].set_index(['date','year','pref']).maxtemp.rename('maxtemp_capitol')\n",
    "df_count = pd.concat([df_count, capitol],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cb33bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#フラグ\n",
    "over30 = (df_count >=30).add_prefix('over30_')\n",
    "over35 = (df_count >=35).add_prefix('over35_')\n",
    "over40 = (df_count >=40).add_prefix('over40_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeac6957",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = pd.concat([df_count, over30, over35, over40],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b971aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count.columns = df_count.columns.str.replace('_maxtemp', '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1b90f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count['count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e5b9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = df_count.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69945c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eea8535",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = \"./data-maxtemp/timeseries-data/jma-maxtemp-temp-by-pref-ts.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d20e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count.to_csv(file_dir, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6396d799",
   "metadata": {},
   "source": [
    "データ内容をチェック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6181c529",
   "metadata": {},
   "outputs": [],
   "source": [
    "#データ漏れのチェック\n",
    "test = df_count.pivot(index='date',columns='pref',values='maxtemp_capitol')\n",
    "test = test.iloc[:-3].fillna('no_data')\n",
    "no_data = test.where(test == 'no_data').dropna(how='all').dropna(how='all',axis=1)\n",
    "no_data = no_data.unstack().dropna().rename('maxtemp_capitol').reset_index()\n",
    "no_data['prec_no'] = no_data.pref.map(points.set_index('pref').prec_no.to_dict())\n",
    "no_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e7cb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#データ欠損分の元データをたどって表示\n",
    "no_data_raw = pd.DataFrame()\n",
    "\n",
    "for idx, row in no_data.iterrows():\n",
    "    pref = row['pref']\n",
    "    date = row['date']\n",
    "    prec_no = row['prec_no']\n",
    "    #filepath\n",
    "    yyyymm = pd.to_datetime(date).strftime('%Y%m')\n",
    "    filepath = f\"./data-maxtemp/timeseries-data-by-points/data-raw/prec-{prec_no}/jma-maxtemp-hs-{prec_no}-{yyyymm}.csv\"\n",
    "    #data by points\n",
    "    data = pd.read_csv(filepath) \n",
    "    capitol = points[(points.capitol==1)&(points.prec_no==prec_no)].name.values[0]\n",
    "    data = data[(data.name==capitol)&(data.date==date.strftime('%Y-%m-%d'))]\n",
    "    no_data_raw = pd.concat([no_data_raw, data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c2d4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#元データがもともと欠損しているので、欠損のままでOK\n",
    "no_data_raw"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.11.3",
   "language": "python",
   "name": "python3.11.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
