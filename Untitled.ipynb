{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "226b18c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#熱中症の救急搬送患者数（総務省）\n",
    "#旧hot_weather\n",
    "#（他のコードもすべて猛暑関連で後から認識しにくいので変更）\n",
    "#ソース：消防庁\n",
    "#毎週火曜（夕方？）に週次データをPDFで発表\n",
    "#https://www.fdma.go.jp/disaster/heatstroke/post3.html\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime, date, timedelta\n",
    "import tabula\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "\n",
    "#1) 週次のPDFファイルのURLを取得する\n",
    "##ポータルの中身をみる\n",
    "url = 'https://www.fdma.go.jp/disaster/heatstroke/post3.html'\n",
    "r = requests.get(url)\n",
    "text = r.text\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "##pdfのURLをいったん全部リストに入れる\n",
    "pattern = re.compile(r'.*heatstroke_sokuhouti.*\\.pdf')\n",
    "href_list = [a['href'] for a in soup.select('div > a[href]') if pattern.match(a['href'])]\n",
    "\n",
    "#2) pdfのURLから中身の表を取り出すファンクションを設定しておく\n",
    "def read_pdf(href):\n",
    "    #URL\n",
    "    parent_dir = 'https://www.fdma.go.jp'\n",
    "    url = f\"https://www.fdma.go.jp{href}\"\n",
    "    \n",
    "    #PDFから表を取得\n",
    "    dfs = tabula.read_pdf(url, stream=True, pages=1)\n",
    "    df = dfs[0].reset_index(drop=True)\n",
    "    \n",
    "    #日付の列を探す\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            idx = df[df[col].str.contains('日付', na=False)].index.to_list()[0]\n",
    "            break\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    #日付に変換\n",
    "    df = df.rename(columns={col:'date'})\n",
    "    df['date'] = df['date'].apply(lambda x: pd.to_datetime(f\"{date.today().year}年{str(x).split(' ')[0]}\", format='%Y年%m月%d日', errors='coerce'))\n",
    "    df = df.set_index('date')\n",
    "    \n",
    "    #カラム名\n",
    "    df.columns = df.iloc[idx+1].to_list()\n",
    "\n",
    "    #ほしいデータ＝「合計」の列を抜粋\n",
    "    col_sum = [col for col in df.columns if '合計'in str(col)]\n",
    "    data= df[col_sum].iloc[:,0].rename('熱中症患者数')\n",
    "    data = pd.to_numeric(data.str.replace(',', ''), errors='coerce')\n",
    "    data = data.reset_index().dropna(subset=['date'])\n",
    "    return data\n",
    "\n",
    "###毎回全部のURLをループするのは時間／安定性の面でよくないので\n",
    "###過去分は蓄積しておき、新規分のみデータを取って積み上げる\n",
    "#3) 前回までのデータ\n",
    "filepath = './data/heatstroke.csv'\n",
    "heatstroke = pd.read_csv(filepath, parse_dates=['date'])\n",
    "\n",
    "#4)追加分のデータ取得\n",
    "#前回までに取得済みのURL\n",
    "with open('./data/heatstroke-pdf-list.json', 'r') as file:\n",
    "    href_list_prev  = json.load(file)   \n",
    "#新規の追加分URL\n",
    "href_list_new = set(href_list) - set(href_list_prev)\n",
    "\n",
    "#新規の追加分URLがあるときのみ\n",
    "for href in href_list_new:\n",
    "    try:\n",
    "        weekly_data = read_pdf(href)\n",
    "        heatstroke = pd.concat([heatstroke, weekly_data])\n",
    "    except:\n",
    "        pass\n",
    "#重複削除\n",
    "heatstroke = heatstroke[~heatstroke.duplicated(subset='date', keep='last')].set_index('date')\n",
    "#日付の隙間を埋める（エラー防止）\n",
    "heatstroke = heatstroke.reindex(pd.date_range(heatstroke.index.min(), heatstroke.index.max()))\n",
    "heatstroke = heatstroke.rename_axis('date').reset_index()\n",
    "\n",
    "#出力\n",
    "#データ\n",
    "heatstroke.to_csv(filepath, index=False)\n",
    "#取得済みPDFのURL\n",
    "with open('./data/heatstroke-pdf-list.json', 'w') as f:\n",
    "    json.dump(href_list, f)\n",
    "\n",
    "#### change log####\n",
    "#役所のPDFでカラムやインデックスを位置で決めうちするのはけっこう危険\n",
    "#やや時間はかかりますが、列名などを特定して取得したほうがよいです\n",
    "#データは数値は数値、日付は日付形式できれいにしておく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "babca052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d840fb8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711381db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#今回分のデータを取得\n",
    "#新規の追加分があるときのみ\n",
    "if len(href_new)>0:\n",
    "    #追加分のデータ取得\n",
    "    for href in href_list_new:\n",
    "        weekly_data = read_pdf(href)\n",
    "        heatstroke = pd.concat([heatstroke, weekly_data])\n",
    "    #重複削除\n",
    "    heatstroke = heatstroke[~heatstroke.duplicated(subset='date', keep='last')].set_index('date')\n",
    "    #日付の隙間を埋める（エラー防止）\n",
    "    heatstroke = heatstroke.reindex(pd.date_range(heatstroke.index.min(), heatstroke.index.max()))\n",
    "    heatstroke = heatstroke.rename_axis('date').reset_index()\n",
    "    print('Updated')\n",
    "else:\n",
    "    print('No updates')\n",
    "    pass\n",
    "\n",
    "#出力\n",
    "#データ\n",
    "heatstroke.to_csv(filepath, index=False)\n",
    "#取得済みPDFのURL\n",
    "with open('./data/heatstroke-pdf-list.json', 'w') as f:\n",
    "    json.dump(href_list, f)\n",
    "\n",
    "#### change log####\n",
    "#役所のPDFでカラムやインデックスを位置で決めうちするのはけっこう危険\n",
    "#やや時間はかかりますが、列名などを特定して取得したほうがよいです\n",
    "#データは数値は数値、日付は日付形式できれいにしておく\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.11.3",
   "language": "python",
   "name": "python3.11.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
